# -*- coding: utf-8 -*-
"""devtest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eY8-Tk7Bh1Bb0lA4iU1Y3nHaaDWcXWb_
"""

# from google.colab import drive
# drive.mount('/content/drive')

import pandas as pd
import valohai
import numpy as numpy

valohai.prepare(
    step='test-model',
    image='tensorflow/tensorflow:2.6.0',
    default_inputs={
        'dataset': 'datum://017f24d5-be37-668b-dc43-c8e58d8c123b',
        # 'model': 'datum://017f1ab8-e325-a00e-3bfa-a74e0427f822'
          'model':  ""
    }
)
with open(valohai.inputs("dataset").path()) as csv_file:
    df = pd.read_csv(csv_file)

#d = pd.read_csv('/content/glcm_dev_data_0097__tf251_all - glcm_dev_data_0097__tf251.csv')

d1 = df.dropna(subset = ["label"])

d1 = d1.dropna(subset = ["vents_count_1"])

d1.isna().sum()

d1['label'] = (d1.label == "Y").astype(int)

d1.shape

d1.columns

X = d1[['contrast11',
       'contrast12', 'contrast13', 'contrast14', 'contrast_avg1', 'contrast21',
       'contrast22', 'contrast23', 'contrast24', 'contrast_avg2',
       'dissimilarity11', 'dissimilarity12', 'dissimilarity13',
       'dissimilarity14', 'dissimilarity_avg1', 'dissimilarity21',
       'dissimilarity22', 'dissimilarity23', 'dissimilarity24',
       'dissimilarity_avg2', 'homogeneity11', 'homogeneity12', 'homogeneity13',
       'homogeneity14', 'homogeneity_avg1', 'homogeneity21', 'homogeneity22',
       'homogeneity23', 'homogeneity24', 'homogeneity_avg_2',
       'energy_feature11', 'energy_feature12', 'energy_feature13',
       'energy_feature14', 'energy_feature_avg1', 'energy_feature21',
       'energy_feature22', 'energy_feature23', 'energy_feature24',
       'energy_feature_avg2', 'correlation_feature11', 'correlation_feature12',
       'correlation_feature13', 'correlation_feature14',
       'correlation_feature_avg1', 'correlation_feature21',
       'correlation_feature22', 'correlation_feature23',
       'correlation_feature24', 'correlation_feature_avg2', 'asm_feature11',
       'asm_feature12', 'asm_feature13', 'asm_feature14', 'asm_feature_avg1',
       'asm_feature21', 'asm_feature22', 'asm_feature23', 'asm_feature24',
       'asm_feature_avg2', 'PIQ_DISTS', 'Cosine similarity', 'td_b7',
       'vents_count_1', 'vents_count_2', 'common_vents_count',
       'similarity_ratio']]

y = d1['label']

#

import joblib
# model_logit = joblib.load('datum://017f1ab8-e325-a00e-3bfa-a74e0427f822')
model_path = valohai.inputs('model').path()
model = joblib.load(model_path)

# Use the loaded model to make predictions
yhat=model.predict(X)
log_prob = model.predict_proba(X)

log_prob_max = [max(log_prob[i]) for i in range(len(log_prob))]

d1['prediction_log_max'] = log_prob_max

d1['prediction_log'] = yhat

from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score

print('Precision score %s' % precision_score(y, yhat))
print('Recall score %s' % recall_score(y, yhat))
print('F1-score score %s' % f1_score(y, yhat))
print('Accuracy score %s' % accuracy_score(y, yhat))
print('confusion matrix %s' % confusion_matrix(y, yhat))

"""## Property Wise"""

df = d1

d1.to_csv("ad.csv")

df=pd.read_csv("ad.csv")

import pandas as pd
import numpy as np
import sys
lists=[]

# df = pd.read_csv('devtest_multiple_input_model1.csv')
props = (np.unique(df['Property'].unique())).tolist()

for p in range(0,len(props)):
  sim_list = []
  prob_list = []
  for j in range(len(df)):
    if df['Property'][j] == props[p]:
      sim_list.append(df["prediction_log"][j])
      prob_list.append((df["prediction_log_max"][j]))
  change_index_list = [idx for idx, element in enumerate(sim_list) if element == 1]
  if len(change_index_list) != 0:
    change_confs = []
    for i in change_index_list:
      change_confs.append(prob_list[i])
    max_v = max(change_confs)
    v = []
    for k in range(len(change_confs)):
      if change_confs[k] == max_v:s
    v.append(k)
    change_index = change_index_list[max(v)]
    for l in range(len(sim_list)):
      if l == change_index:
        sim_list[l] = 1
      else:
        sim_list[l] = 0
  else:
    for m in range(len(sim_list)):
      sim_list[m] = 0
  for f in range(len(sim_list)):
    df1={"Property":props[p],"prop_pred":sim_list[f]}
    lists.append(df1)
  # df1 = pd.DataFrame(sim_list,columns=['Prop_Pred'])
  # df1['Property'] = props[p]
  # df1.to_csv('PROP_dev_model1.csv',mode="a")
df1=pd.DataFrame(lists)
print(df1)
# df.to_csv("blah.csv")

df["prop_pred"]=df1["prop_pred"]

testY=df["label"]

yhat=df["prop_pred"]

from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score
print('Precision score %s' % precision_score(testY, yhat))
print('Recall score %s' % recall_score(testY, yhat))
print('F1-score score %s' % f1_score(testY, yhat))
print('Accuracy score %s' % accuracy_score(testY, yhat))
print('confusion matrix %s' % confusion_matrix(testY, yhat))





